# üéØ Fine-Tune PhoBERT cho AgriBot (Step-by-Step)

> **M·ª•c ti√™u:** hu·∫•n luy·ªán (fine-tune) PhoBERT cho b√†i to√°n Intent Classification & NER, s·ª≠ d·ª•ng ƒë·ªÉ n√¢ng ch·∫•t l∆∞·ª£ng AI chatbot. T√†i li·ªáu n√†y d√†nh cho ng∆∞·ªùi **kh√¥ng c√≥ n·ªÅn t·∫£ng Python**, n√™n c√°c b∆∞·ªõc ƒë∆∞·ª£c m√¥ t·∫£ chi ti·∫øt.

---

## üß† T·ªïng quan lu·ªìng ch·∫°y

```mermaid
flowchart LR
    A[1. Chu·∫©n b·ªã d·ªØ li·ªáu] --> B[2. Thi·∫øt l·∫≠p m√¥i tr∆∞·ªùng]
    B --> C[3. Hu·∫•n luy·ªán Intent]
    C --> D[4. Hu·∫•n luy·ªán NER]
    D --> E[5. Ki·ªÉm th·ª≠ m√¥ h√¨nh]
    E --> F[6. T√≠ch h·ª£p v√†o Python AI Service]
    F --> G[7. Kh·ªüi ƒë·ªông l·∫°i service]
```

- **Intent model**: Nh·∫≠n di·ªán c√¢u h·ªèi thu·ªôc lo·∫°i n√†o (doanh thu, thi·∫øt b·ªã, ki·∫øn th·ª©c‚Ä¶).
- **NER model**: Tr√≠ch xu·∫•t entity (ng√†y, ti·ªÅn, t√™n c√¢y, thi·∫øt b·ªã‚Ä¶).
- K·∫øt qu·∫£ fine-tune ƒë∆∞·ª£c ƒë·∫∑t v√†o `apps/python-ai-service/models/...` ƒë·ªÉ service t·ª± d√πng.

---

## 0Ô∏è‚É£ Chu·∫©n b·ªã ban ƒë·∫ßu

| Th√†nh ph·∫ßn | Y√™u c·∫ßu |
|------------|---------|
| M√°y t√≠nh   | Windows 10/11 (khuy·∫øn ngh·ªã) |
| Python     | Python 3.10+ (c√†i ƒë·∫∑t s·∫µn) |
| C√¥ng c·ª•    | Git (t√πy ch·ªçn), VS Code (khuy·∫øn ngh·ªã) |
| GPU        | Kh√¥ng b·∫Øt bu·ªôc (c√≥ GPU train nhanh h∆°n) |
| Dung l∆∞·ª£ng | ~5 GB tr·ªëng (model + d·ªØ li·ªáu) |

**Ki·ªÉm tra Python:**
```powershell
python --version
```
N·∫øu ch∆∞a c√≥, t·∫£i t·∫°i https://www.python.org/downloads/ (ch·ªçn Add to PATH khi c√†i).

---

## 1Ô∏è‚É£ Chu·∫©n b·ªã d·ªØ li·ªáu hu·∫•n luy·ªán

### 1.1 C·∫•u tr√∫c th∆∞ m·ª•c l√†m vi·ªác

```
ex/
‚îú‚îÄ‚îÄ apps/
‚îÇ   ‚îî‚îÄ‚îÄ python-ai-service/
‚îÇ       ‚îú‚îÄ‚îÄ models/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ intent_classifier/   (ƒë·ªÉ ch·ª©a checkpoint fine-tune intent)
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ ner_extractor/       (ƒë·ªÉ ch·ª©a checkpoint fine-tune NER)
‚îÇ       ‚îú‚îÄ‚îÄ train/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ data/                (ƒë·∫∑t file CSV hu·∫•n luy·ªán)
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ scripts/             (script hu·∫•n luy·ªán)
‚îÇ       ‚îî‚îÄ‚îÄ ...
```

> B·∫°n c√≥ th·ªÉ t·∫°o th∆∞ m·ª•c `train/` ƒë·ªÉ ch·ª©a d·ªØ li·ªáu v√† script. N·∫øu ch∆∞a c√≥, t·∫°o b·∫±ng VS Code ho·∫∑c File Explorer.

### 1.2 Chu·∫©n b·ªã d·ªØ li·ªáu Intent

1. V√†o `apps/python-ai-service/train/data/` (t·∫°o th∆∞ m·ª•c n·∫øu ch∆∞a c√≥).
2. T·∫°o file `intent_data.csv` v·ªõi n·ªôi dung m·∫´u (c√≥ th·ªÉ d·ª±a theo y√™u c·∫ßu th·ª±c t·∫ø, c√†ng nhi·ªÅu c√¢u c√†ng t·ªët):
   ```csv
   text,label
   "doanh thu th√°ng n√†y l√† bao nhi√™u",0
   "chi ph√≠ t∆∞·ªõi ti√™u th√°ng 3",0
   "c√°ch tr·ªìng c√† chua",1
   "thu ho·∫°ch c√¢y b·∫Øp khi n√†o",1
   "b·∫≠t h·ªá th·ªëng t∆∞·ªõi",2
   "t·∫Øt m√°y b∆°m",2
   "t∆∞·ªõi n∆∞·ªõc cho lu·ªëng A",3
   "ph√¢n t√≠ch s·ªë li·ªáu farm",4
   "d·ªØ li·ªáu c·∫£m bi·∫øn nhi·ªát ƒë·ªô",7
   "t·∫°o b·∫£n ghi m·ªõi",8
   "c·∫≠p nh·∫≠t th√¥ng tin farm",9
   "x√≥a d·ªØ li·ªáu c≈©",10
   ```
3. **Mapping label** (ƒë·ªìng b·ªô v·ªõi NestJS):

   | Label | IntentType t∆∞∆°ng ·ª©ng |
   |-------|----------------------|
   | 0     | financial_query |
   | 1     | crop_query |
   | 2     | device_control |
   | 3     | activity_query |
   | 4     | analytics_query |
   | 5     | farm_query |
   | 6     | sensor_query |
   | 7     | create_record |
   | 8     | update_record |
   | 9     | delete_record |
   | 10    | knowledge_query (t√πy ch·ªçn) |

   > B·∫°n c√≥ th·ªÉ th√™m c·ªôt `intent_name` ƒë·ªÉ ƒë·ªçc d·ªÖ h∆°n (kh√¥ng b·∫Øt bu·ªôc). 

### 1.3 Chu·∫©n b·ªã d·ªØ li·ªáu NER

1. T·∫°o file `ner_data.jsonl` (m·ªói d√≤ng l√† 1 json record). V√≠ d·ª•:
   ```json
   {"text": "Doanh thu th√°ng 10 l√† 200 tri·ªáu", "entities": [[11, 16, "DATE"], [24, 32, "MONEY"]]}
   {"text": "T∆∞·ªõi n∆∞·ªõc cho lu·ªëng A", "entities": [[16, 23, "FARM_AREA"]]}
   {"text": "B·∫≠t m√°y b∆°m n∆∞·ªõc", "entities": [[4, 11, "DEVICE"]]}
   ```
   - C·∫•u tr√∫c `entities`: `[start_index, end_index, entity_type]` theo v·ªã tr√≠ trong chu·ªói.
   - C√°c entity types n√™n kh·ªõp `NERExtractor.ENTITY_LABELS` (DATE, MONEY, CROP, AREA, DEVICE, ACTIVITY, METRIC).

> N·∫øu ch∆∞a c√≥ d·ªØ li·ªáu th·∫≠t, c√≥ th·ªÉ t·∫°m d√πng d·ªØ li·ªáu m·∫´u (√≠t nh·∫•t 50-100 c√¢u m·ªói intent/entity).

---

## 2Ô∏è‚É£ Thi·∫øt l·∫≠p m√¥i tr∆∞·ªùng (Windows)

### 2.1 T·∫°o virtual environment (khuy·∫øn ngh·ªã)

```powershell
cd apps/python-ai-service

# T·∫°o virtualenv (n·∫øu ch∆∞a c√≥)
python -m venv venv

# K√≠ch ho·∫°t
venv\Scripts\activate
```

Sau khi k√≠ch ho·∫°t, prompt s·∫Ω c√≥ d·∫°ng `(venv) C:\...`.

### 2.2 C√†i dependencies

Trong m√¥i tr∆∞·ªùng ƒë√£ k√≠ch ho·∫°t:
```powershell
pip install --upgrade pip
pip install -r requirements.txt

# N·∫øu thi·∫øu th∆∞ vi·ªán cho training, c√†i th√™m:
pip install transformers datasets torch pandas scikit-learn numpy accelerate evaluate seqeval
```

> N·∫øu m√°y kh√¥ng c√≥ GPU, `torch` s·∫Ω t·ª± c√†i b·∫£n CPU (ch·∫°y ch·∫≠m h∆°n).

---

## 3Ô∏è‚É£ Hu·∫•n luy·ªán Intent Classification (Local)

### 3.1 T·∫°o script training

1. T·∫°o file `apps/python-ai-service/train/scripts/train_intent.py` v·ªõi n·ªôi dung m·∫´u:
   ```python
   import pandas as pd
   from datasets import Dataset
   from sklearn.model_selection import train_test_split
   import torch
   from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments

   # ƒê∆∞·ªùng d·∫´n d·ªØ li·ªáu & n∆°i l∆∞u model
   DATA_PATH = "../data/intent_data.csv"
   OUTPUT_DIR = "../../models/intent_classifier"

   df = pd.read_csv(DATA_PATH)

   # T√°ch train/validation
   train_texts, val_texts, train_labels, val_labels = train_test_split(
       df['text'], df['label'], test_size=0.2, random_state=42, stratify=df['label']
   )

   tokenizer = AutoTokenizer.from_pretrained("vinai/phobert-base")

   def tokenize(batch):
       return tokenizer(batch['text'], truncation=True, padding='max_length', max_length=256)

   train_dataset = Dataset.from_dict({"text": train_texts, "label": train_labels})
   val_dataset = Dataset.from_dict({"text": val_texts, "label": val_labels})

   train_dataset = train_dataset.map(tokenize, batched=True)
   val_dataset = val_dataset.map(tokenize, batched=True)

   train_dataset = train_dataset.rename_column("label", "labels")
   val_dataset = val_dataset.rename_column("label", "labels")

   model = AutoModelForSequenceClassification.from_pretrained(
       "vinai/phobert-base", num_labels=df['label'].nunique()
   )

   training_args = TrainingArguments(
       output_dir=OUTPUT_DIR,
       evaluation_strategy="epoch",
       save_strategy="epoch",
       learning_rate=2e-5,
       per_device_train_batch_size=8,
       per_device_eval_batch_size=8,
       num_train_epochs=4,
       weight_decay=0.01,
       load_best_model_at_end=True,
       metric_for_best_model="accuracy",
   )

   def compute_metrics(eval_pred):
       import numpy as np
       from datasets import load_metric
       metric = load_metric("accuracy")
       logits, labels = eval_pred
       predictions = np.argmax(logits, axis=-1)
       return metric.compute(predictions=predictions, references=labels)

   trainer = Trainer(
       model=model,
       args=training_args,
       train_dataset=train_dataset,
       eval_dataset=val_dataset,
       tokenizer=tokenizer,
       compute_metrics=compute_metrics,
   )

   trainer.train()
   trainer.save_model(OUTPUT_DIR)
   tokenizer.save_pretrained(OUTPUT_DIR)
   ```

2. Ch·∫°y script:
   ```powershell
   cd apps/python-ai-service/train/scripts
   python train_intent.py
   ```
3. K·∫øt qu·∫£: Checkpoint ƒë∆∞·ª£c l∆∞u t·∫°i `apps/python-ai-service/models/intent_classifier/`.

---

## 4Ô∏è‚É£ Hu·∫•n luy·ªán NER (PhoBERT Token Classification)

### 4.1 Script m·∫´u

T·∫°o `apps/python-ai-service/train/scripts/train_ner.py`:
```python
import json
import os
from datasets import Dataset,
from sklearn.model_selection import train_test_split
from transformers import AutoTokenizer, AutoModelForTokenClassification, DataCollatorForTokenClassification, Trainer, TrainingArguments

DATA_PATH = "../data/ner_data.jsonl"
OUTPUT_DIR = "../../models/ner_extractor"

# Load data jsonl
def load_dataset(path):
    texts, entities = [], []
    with open(path, "r", encoding="utf-8") as f:
        for line in f:
            item = json.loads(line)
            texts.append(item["text"])
            entities.append(item["entities"])
    return texts, entities

texts, entities = load_dataset(DATA_PATH)

# Tokenizer & label mapping
label_list = ["O", "B-DATE", "I-DATE", "B-MONEY", "I-MONEY", "B-CROP", "I-CROP", "B-AREA", "I-AREA", "B-DEVICE", "I-DEVICE", "B-ACTIVITY", "I-ACTIVITY", "B-METRIC", "I-METRIC"]
label_to_id = {label: i for i, label in enumerate(label_list)}

model_name = "vinai/phobert-base"
tokenizer = AutoTokenizer.from_pretrained(model_name)

# Convert entity annotations sang label sequence cho t·ª´ng token (ph·ª©c t·∫°p h∆°n intent)
# ƒê·ªÉ ƒë∆°n gi·∫£n, b·∫°n c√≥ th·ªÉ d√πng c√°c th∆∞ vi·ªán h·ªó tr·ª£ (v√≠ d·ª•: seqeval), ho·∫∑c tham kh·∫£o script trong huggingface.
# ·ªû ƒë√¢y, khuy·∫øn ngh·ªã s·ª≠ d·ª•ng notebook m·∫´u trong HuggingFace course: "Token Classification".

# => N·∫øu b·∫°n c·∫ßn script c·ª• th·ªÉ h∆°n, xem t√†i li·ªáu ƒëi k√®m (FINE_TUNING_GUIDE.md) ƒë·ªÉ copy script chi ti·∫øt.

```

> Hu·∫•n luy·ªán NER ph·ª©c t·∫°p h∆°n v√¨ ph·∫£i map entity theo token. N·∫øu b·∫°n ch∆∞a quen, ∆∞u ti√™n tham kh·∫£o notebook chu·∫©n c·ªßa HuggingFace: https://huggingface.co/transformers/tasks/token_classification v√† chuy·ªÉn to√†n b·ªô b∆∞·ªõc th·ª±c thi sang m√¥i tr∆∞·ªùng local b·∫±ng Python venv ·ªü tr√™n.

### 4.2 G·ª£i √Ω nhanh (n·∫øu kh√¥ng mu·ªën t·ª± code)

- S·ª≠ d·ª•ng **notebook ch√≠nh th·ª©c** c·ªßa HuggingFace cho token classification (b·∫°n ch·ªâ c·∫ßn thay d·ªØ li·ªáu c·ªßa m√¨nh):
  - https://github.com/huggingface/notebooks/blob/main/examples/token_classification.ipynb
- Thay `model_name = "vinai/phobert-base"`.
- Ch·ªânh `label_list` theo entity c·ªßa AgriBot.
- Sau khi train xong, download folder `ner_extractor` v√† ƒë·∫∑t v√†o `apps/python-ai-service/models/ner_extractor/`.

---

## 5Ô∏è‚É£ Ki·ªÉm th·ª≠ m√¥ h√¨nh ƒë√£ fine-tune

### 5.1 Intent

T·∫°o script `apps/python-ai-service/train/scripts/test_intent.py`:
```python
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch

MODEL_PATH = "../../models/intent_classifier"

tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)
model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH)

INTENT_LABELS = [
    "financial_query", "crop_query", "device_control",
    "activity_query", "analytics_query", "farm_query",
    "sensor_query", "create_record", "update_record",
    "delete_record", "knowledge_query"
]

def predict_intent(text):
    inputs = tokenizer(text, return_tensors="pt", truncation=True, max_length=256)
    with torch.no_grad():
        outputs = model(**inputs)
        probs = torch.softmax(outputs.logits, dim=-1)
        idx = torch.argmax(probs, dim=-1).item()
        confidence = probs[0][idx].item()
    return INTENT_LABELS[idx], confidence

samples = [
    "Doanh thu th√°ng n√†y l√† bao nhi√™u",
    "B·∫≠t h·ªá th·ªëng t∆∞·ªõi",
    "C√°ch tr·ªìng c√† chua"
]

for text in samples:
    intent, conf = predict_intent(text)
    print(f"{text} -> {intent} ({conf:.2f})")
```

Ch·∫°y:
```powershell
python test_intent.py
```

### 5.2 NER

N·∫øu ƒë√£ fine-tune NER, t·∫°o `test_ner.py`:
```python
from transformers import AutoTokenizer, AutoModelForTokenClassification
import torch

MODEL_PATH = "../../models/ner_extractor"

label_list = ["O", "B-DATE", "I-DATE", "B-MONEY", "I-MONEY", "B-CROP", "I-CROP", "B-AREA", "I-AREA", "B-DEVICE", "I-DEVICE", "B-ACTIVITY", "I-ACTIVITY", "B-METRIC", "I-METRIC"]

tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)
model = AutoModelForTokenClassification.from_pretrained(MODEL_PATH)

text = "Thu√™ nh√¢n c√¥ng t·ªën 10 tri·ªáu trong th√°ng 9"
inputs = tokenizer(text, return_tensors="pt", return_offsets_mapping=True)
with torch.no_grad():
    outputs = model(**inputs)
    predictions = torch.argmax(outputs.logits, dim=-1)[0]

offset_mapping = inputs["offset_mapping"][0]
result = []
for idx, pred in enumerate(predictions):
    label = label_list[pred.item()]
    if label != "O":
        start, end = offset_mapping[idx]
        result.append({
            "label": label,
            "text": text[start:end],
            "position": (start, end)
        })

print(result)
```

---

## 6Ô∏è‚É£ T√≠ch h·ª£p v√†o Python AI Service

1. ƒê·∫£m b·∫£o c√°c checkpoint ƒë√£ ƒë∆∞·ª£c copy ƒë√∫ng:
   - `apps/python-ai-service/models/intent_classifier/` ch·ª©a `config.json`, `pytorch_model.bin`, `tokenizer.json`, ...
   - `apps/python-ai-service/models/ner_extractor/` t∆∞∆°ng t·ª±.

2. `IntentClassifier.load_model()` v√† `NERExtractor.load_model()` ƒë√£ c√≥ logic ki·ªÉm tra ƒë∆∞·ªùng d·∫´n fine-tune. N·∫øu th·∫•y log ‚ÄúFine-tuned model not found‚Äù nghƒ©a l√† th∆∞ m·ª•c r·ªóng ho·∫∑c sai ƒë∆∞·ªùng d·∫´n.

> N·∫øu b·∫°n mu·ªën ch·ªâ r√µ ƒë∆∞·ªùng d·∫´n kh√°c, ch·ªânh trong file `apps/python-ai-service/src/models/intent_classifier.py` & `ner_extractor.py` (bi·∫øn `fine_tuned_path`).

---

## 7Ô∏è‚É£ Kh·ªüi ƒë·ªông l·∫°i Python AI Service

```powershell
cd apps/python-ai-service
venv\Scripts\activate
python src/main.py
```

Log k·ª≥ v·ªçng:
```
üì¶ Loading Intent Classifier (PhoBERT)...
Loading fine-tuned model from ./models/intent_classifier...
üì¶ Loading NER Extractor (PhoBERT)...
Loading fine-tuned model from ./models/ner_extractor...
üéâ Python AI Service ready!
```

Test nhanh:
```powershell
curl -X POST http://localhost:8000/intent/classify ^
  -H "Content-Type: application/json" ^
  -d "{\"text\": \"Doanh thu th√°ng n√†y bao nhi√™u\"}"
```
D·ª± ki·∫øn tr·∫£ v·ªÅ `financial_query` v·ªõi confidence cao >0.8.

---

## ‚ùì FAQ nhanh

| C√¢u h·ªèi | Gi·∫£i ƒë√°p |
|---------|----------|
| **Kh√¥ng c√≥ GPU, train ƒë∆∞·ª£c kh√¥ng?** | ƒê∆∞·ª£c, nh∆∞ng ch·∫≠m h∆°n. D·ªØ li·ªáu nh·ªè v·∫´n train ·ªïn (10-50 ph√∫t). |
| **D·ªØ li·ªáu √≠t c√≥ train ƒë∆∞·ª£c kh√¥ng?** | C√≥ th·ªÉ b·∫Øt ƒë·∫ßu v·ªõi 20-50 c√¢u m·ªói intent/entity. C√†ng nhi·ªÅu d·ªØ li·ªáu c√†ng ch√≠nh x√°c. |
| **C·∫ßn bao l√¢u?** | Chu·∫©n b·ªã + train intent: ~30 ph√∫t. NER ph·ª©c t·∫°p h∆°n: 1-2 gi·ªù (n·∫øu kh√¥ng quen). |
| **L∆∞u m√¥ h√¨nh ·ªü ƒë√¢u?** | `apps/python-ai-service/models/intent_classifier/` v√† `models/ner_extractor/`. |
| **Service v·∫´n c·∫£nh b√°o fallback?** | Ki·ªÉm tra l·∫°i th∆∞ m·ª•c checkpoint v√† ch·∫Øc ch·∫Øn service ch·∫°y trong c√πng m√¥i tr∆∞·ªùng. |

---

## ‚úÖ Checklist ho√†n th√†nh

- [ ] C√†i Python & k√≠ch ho·∫°t virtualenv
- [ ] Chu·∫©n b·ªã `intent_data.csv` & (tu·ª≥ ch·ªçn) `ner_data.jsonl`
- [ ] C√†i dependencies training
- [ ] Ch·∫°y `train_intent.py`
- [ ] (Tu·ª≥ ch·ªçn) Ch·∫°y `train_ner.py` ho·∫∑c notebook HuggingFace (local)
- [ ] Copy checkpoint v√†o `apps/python-ai-service/models/...`
- [ ] Test v·ªõi `test_intent.py` / `test_ner.py`
- [ ] Kh·ªüi ƒë·ªông l·∫°i Python service & ki·ªÉm tra

Ch√∫c b·∫°n hu·∫•n luy·ªán th√†nh c√¥ng! üöÄ N·∫øu c·∫ßn script m·∫´u chi ti·∫øt h∆°n, b·∫°n c√≥ th·ªÉ xem th√™m t·∫°i `FINE_TUNING_GUIDE.md` ho·∫∑c li√™n h·ªá team DevOps h·ªó tr·ª£.
