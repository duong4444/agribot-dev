{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸŒ¾ Train Intent Classifier - PhoBERT for Agricultural Chatbot\n",
    "\n",
    "Notebook nÃ y dÃ¹ng Ä‘á»ƒ train láº¡i model Intent Classification vá»›i data má»›i.\n",
    "\n",
    "**Model**: PhoBERT (vinai/phobert-base)  \n",
    "**Task**: Multi-class Intent Classification  \n",
    "**Labels**: knowledge_query, financial_query, device_control, sensor_query, unknown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¦ 1. CÃ i Ä‘áº·t thÆ° viá»‡n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers datasets torch scikit-learn pandas numpy seqeval accelerate\n",
    "\n",
    "# Táº¯t wandb Ä‘á»ƒ trÃ¡nh yÃªu cáº§u API key\n",
    "import os\n",
    "os.environ['WANDB_DISABLED'] = 'true'\n",
    "print(\"âœ… ÄÃ£ táº¯t Weights & Biases tracking\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ 2. Upload file data\n",
    "\n",
    "Upload file `intent_data_augmented_5intents.csv` tá»« mÃ¡y cá»§a báº¡n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import pandas as pd\n",
    "\n",
    "# Upload file CSV\n",
    "print(\"ğŸ“¤ Vui lÃ²ng upload file intent_data_augmented_5intents.csv\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Láº¥y tÃªn file Ä‘áº§u tiÃªn Ä‘Æ°á»£c upload\n",
    "data_file = list(uploaded.keys())[0]\n",
    "print(f\"âœ… ÄÃ£ upload file: {data_file}\")\n",
    "\n",
    "# Äá»c vÃ  kiá»ƒm tra data\n",
    "df = pd.read_csv(data_file)\n",
    "print(f\"\\nğŸ“Š Tá»•ng sá»‘ máº«u: {len(df)}\")\n",
    "print(f\"\\nğŸ“‹ CÃ¡c cá»™t: {df.columns.tolist()}\")\n",
    "print(f\"\\nğŸ·ï¸ PhÃ¢n bá»‘ labels:\")\n",
    "print(df['label'].value_counts())\n",
    "print(f\"\\nğŸ‘€ Xem 5 máº«u Ä‘áº§u tiÃªn:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”§ 3. Chuáº©n bá»‹ dá»¯ liá»‡u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer\n",
    "import json\n",
    "\n",
    "# Kiá»ƒm tra GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"ğŸ–¥ï¸ Device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# Táº¡o label mapping\n",
    "unique_labels = sorted(df['label'].unique())\n",
    "label_to_id = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "id_to_label = {idx: label for label, idx in label_to_id.items()}\n",
    "\n",
    "print(f\"\\nğŸ·ï¸ Label mapping:\")\n",
    "for label, idx in label_to_id.items():\n",
    "    print(f\"   {idx}: {label}\")\n",
    "\n",
    "# ThÃªm cá»™t label_id\n",
    "df['label_id'] = df['label'].map(label_to_id)\n",
    "\n",
    "# Chia train/val/test (70/15/15)\n",
    "train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42, stratify=df['label'])\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42, stratify=temp_df['label'])\n",
    "\n",
    "print(f\"\\nğŸ“Š PhÃ¢n chia dá»¯ liá»‡u:\")\n",
    "print(f\"   Train: {len(train_df)} máº«u\")\n",
    "print(f\"   Val:   {len(val_df)} máº«u\")\n",
    "print(f\"   Test:  {len(test_df)} máº«u\")\n",
    "\n",
    "# Load tokenizer\n",
    "model_name = \"vinai/phobert-base\"\n",
    "print(f\"\\nğŸ”¤ Loading tokenizer: {model_name}\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "print(\"âœ… Tokenizer loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ 4. Táº¡o Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class IntentDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=256):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Táº¡o datasets\n",
    "train_dataset = IntentDataset(\n",
    "    train_df['text'].tolist(),\n",
    "    train_df['label_id'].tolist(),\n",
    "    tokenizer\n",
    ")\n",
    "\n",
    "val_dataset = IntentDataset(\n",
    "    val_df['text'].tolist(),\n",
    "    val_df['label_id'].tolist(),\n",
    "    tokenizer\n",
    ")\n",
    "\n",
    "test_dataset = IntentDataset(\n",
    "    test_df['text'].tolist(),\n",
    "    test_df['label_id'].tolist(),\n",
    "    tokenizer\n",
    ")\n",
    "\n",
    "print(\"âœ… Datasets created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸš€ 5. Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Load model\n",
    "print(f\"ğŸ¤– Loading model: {model_name}\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=len(label_to_id)\n",
    ")\n",
    "model.to(device)\n",
    "print(\"âœ… Model loaded\")\n",
    "\n",
    "# Äá»‹nh nghÄ©a metrics\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    \n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, preds, average='weighted', zero_division=0\n",
    "    )\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./intent_classifier_output',\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=50,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "    save_total_limit=2,\n",
    "    fp16=torch.cuda.is_available(),  # Mixed precision náº¿u cÃ³ GPU\n",
    "    report_to=\"none\",  # Táº¯t wandb/tensorboard\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    ")\n",
    "\n",
    "print(\"\\nğŸ‹ï¸ Báº¯t Ä‘áº§u training...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Train\n",
    "trainer.train()\n",
    "\n",
    "print(\"\\nâœ… Training hoÃ n thÃ nh!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š 6. ÄÃ¡nh giÃ¡ Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate trÃªn test set\n",
    "print(\"ğŸ“Š ÄÃ¡nh giÃ¡ trÃªn Test Set:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "test_results = trainer.evaluate(test_dataset)\n",
    "print(f\"\\nğŸ“ˆ Test Results:\")\n",
    "for key, value in test_results.items():\n",
    "    print(f\"   {key}: {value:.4f}\")\n",
    "\n",
    "# Detailed classification report\n",
    "predictions = trainer.predict(test_dataset)\n",
    "preds = predictions.predictions.argmax(-1)\n",
    "labels = predictions.label_ids\n",
    "\n",
    "print(f\"\\nğŸ“‹ Classification Report:\")\n",
    "print(\"=\" * 60)\n",
    "print(classification_report(\n",
    "    labels,\n",
    "    preds,\n",
    "    target_names=[id_to_label[i] for i in range(len(id_to_label))],\n",
    "    digits=4\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ§ª 7. Test vá»›i cÃ¢u máº«u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_intent(text, model, tokenizer, label_mapping):\n",
    "    \"\"\"Dá»± Ä‘oÃ¡n intent cho má»™t cÃ¢u\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=256,\n",
    "        padding=True\n",
    "    )\n",
    "    \n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        probs = torch.softmax(logits, dim=-1)\n",
    "    \n",
    "    # Top 3 predictions\n",
    "    top_probs, top_indices = torch.topk(probs[0], k=3)\n",
    "    \n",
    "    print(f\"\\nğŸ“ Text: {text}\")\n",
    "    print(f\"\\nğŸ¯ Predictions:\")\n",
    "    for prob, idx in zip(top_probs.cpu().numpy(), top_indices.cpu().numpy()):\n",
    "        intent = label_mapping[idx]\n",
    "        print(f\"   {intent}: {prob:.4f} ({prob*100:.2f}%)\")\n",
    "\n",
    "# Test vá»›i cÃ¡c cÃ¢u máº«u\n",
    "test_sentences = [\n",
    "    \"Máº­t Ä‘á»™ trá»“ng kinh giá»›i thÃ­ch há»£p?\",\n",
    "    \"Dá»¯ liá»‡u cáº£m biáº¿n 1 giá» trÆ°á»›c Ä‘i\",\n",
    "    \"LÃªn lá»‹ch mÃ¡y bÆ¡m má»—i 2 tiáº¿ng.\",\n",
    "    \"BÃ¡o cÃ¡o chi phÃ­ theo tá»«ng háº¡ng má»¥c.\",\n",
    "    \"Báº¡n lÃ  ai?\"\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ§ª TEST Vá»šI CÃC CÃ‚U MáºªU\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for sentence in test_sentences:\n",
    "    predict_intent(sentence, model, tokenizer, id_to_label)\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ’¾ 8. LÆ°u Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Táº¡o thÆ° má»¥c output\n",
    "output_dir = \"./intent_classifier_final\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(f\"ğŸ’¾ LÆ°u model vÃ o: {output_dir}\")\n",
    "\n",
    "# LÆ°u model vÃ  tokenizer\n",
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "# LÆ°u label mapping\n",
    "label_mapping = {\n",
    "    \"label_to_id\": label_to_id,\n",
    "    \"id_to_label\": id_to_label\n",
    "}\n",
    "\n",
    "with open(os.path.join(output_dir, \"label_mapping.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(label_mapping, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"âœ… Model Ä‘Ã£ Ä‘Æ°á»£c lÆ°u!\")\n",
    "print(f\"\\nğŸ“ CÃ¡c file trong {output_dir}:\")\n",
    "for file in os.listdir(output_dir):\n",
    "    print(f\"   - {file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¥ 9. Download Model vá» mÃ¡y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NÃ©n thÆ° má»¥c model thÃ nh file zip\n",
    "print(\"ğŸ“¦ Äang nÃ©n model...\")\n",
    "shutil.make_archive(\"intent_classifier_final\", 'zip', output_dir)\n",
    "print(\"âœ… ÄÃ£ nÃ©n xong!\")\n",
    "\n",
    "# Download file zip\n",
    "print(\"\\nğŸ“¥ Download file zip vá» mÃ¡y...\")\n",
    "files.download(\"intent_classifier_final.zip\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"âœ… HOÃ€N THÃ€NH!\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nğŸ“ HÆ°á»›ng dáº«n sá»­ dá»¥ng:\")\n",
    "print(\"   1. Giáº£i nÃ©n file intent_classifier_final.zip\")\n",
    "print(\"   2. Copy toÃ n bá»™ ná»™i dung vÃ o thÆ° má»¥c:\")\n",
    "print(\"      apps/python-ai-service/models/intent_classifier/\")\n",
    "print(\"   3. Restart Python AI Service\")\n",
    "print(\"   4. Test API Ä‘á»ƒ kiá»ƒm tra model má»›i\")\n",
    "print(\"\\nğŸ‰ ChÃºc má»«ng! Model Ä‘Ã£ Ä‘Æ°á»£c train thÃ nh cÃ´ng!\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
