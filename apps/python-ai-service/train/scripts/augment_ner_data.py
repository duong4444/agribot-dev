"""
Data Augmentation Script for NER Training
Tá»± Ä‘á»™ng táº¡o thÃªm dá»¯ liá»‡u training tá»« data hiá»‡n cÃ³
"""

import pandas as pd
import json
import random
from pathlib import Path

# Synonym dictionaries for augmentation
CROP_SYNONYMS = {
    "cÃ  chua": ["cÃ  chua", "quáº£ cÃ  chua", "cÃ¢y cÃ  chua"],
    "cÃ  phÃª": ["cÃ  phÃª", "cafe", "cÃ¢y cÃ  phÃª"],
    "lÃºa": ["lÃºa", "thÃ³c", "cÃ¢y lÃºa"],
    "ngÃ´": ["ngÃ´", "báº¯p", "cÃ¢y ngÃ´"],
    "á»›t": ["á»›t", "tiÃªu", "cÃ¢y á»›t"],
}

AREA_SYNONYMS = {
    "ruá»™ng": ["ruá»™ng", "thá»­a ruá»™ng", "khu ruá»™ng"],
    "vÆ°á»n": ["vÆ°á»n", "khu vÆ°á»n"],
    "nhÃ  kÃ­nh": ["nhÃ  kÃ­nh", "greenhouse"],
}

DEVICE_SYNONYMS = {
    "mÃ¡y bÆ¡m": ["mÃ¡y bÆ¡m", "bÆ¡m nÆ°á»›c", "thiáº¿t bá»‹ bÆ¡m"],
    "sensor": ["sensor", "cáº£m biáº¿n", "thiáº¿t bá»‹ cáº£m biáº¿n"],
}

# Templates for generating new sentences
TEMPLATES = [
    # CROP_NAME templates
    ("cÃ¡ch trá»“ng {crop}", "CROP_NAME"),
    ("ká»¹ thuáº­t trá»“ng {crop}", "CROP_NAME"),
    ("chÄƒm sÃ³c {crop}", "CROP_NAME"),
    ("bÃ³n phÃ¢n cho {crop}", "CROP_NAME"),
    ("tÆ°á»›i nÆ°á»›c cho {crop}", "CROP_NAME"),
    
    # AREA templates
    ("táº¡i {area}", "AREA"),
    ("á»Ÿ {area}", "AREA"),
    ("khu vá»±c {area}", "AREA"),
    
    # Multi-entity templates
    ("trá»“ng {crop} táº¡i {area}", ["CROP_NAME", "AREA"]),
    ("bÃ³n phÃ¢n cho {crop} á»Ÿ {area}", ["CROP_NAME", "AREA"]),
    ("{activity} {crop} vÃ o {date}", ["ACTIVITY", "CROP_NAME", "DATE"]),
]


def load_original_data():
    """Load original training data"""
    csv_path = Path(__file__).parent.parent / "data" / "ner_data.csv"
    df = pd.read_csv(csv_path, encoding='utf-8')
    print(f"ğŸ“Š Loaded {len(df)} original examples")
    return df


def synonym_replacement(text, entities_json, replacement_dict):
    """Replace entities with synonyms"""
    try:
        entities = json.loads(entities_json)
        new_examples = []
        
        for entity in entities:
            entity_value = entity['value']
            
            # Find synonyms
            if entity_value in replacement_dict:
                synonyms = replacement_dict[entity_value]
                
                for synonym in synonyms:
                    if synonym != entity_value:  # Skip original
                        # Replace in text
                        new_text = text.replace(entity_value, synonym)
                        
                        # Update entity
                        new_entities = []
                        for ent in entities:
                            new_ent = ent.copy()
                            if ent['value'] == entity_value:
                                # Update positions
                                old_len = len(entity_value)
                                new_len = len(synonym)
                                diff = new_len - old_len
                                
                                new_ent['value'] = synonym
                                new_ent['end'] = new_ent['start'] + new_len
                            new_entities.append(new_ent)
                        
                        new_examples.append({
                            'text': new_text,
                            'entities': json.dumps(new_entities, ensure_ascii=False)
                        })
        
        return new_examples
    except:
        return []


def generate_from_templates(num_samples=200):
    """Generate new examples from templates"""
    generated = []
    
    crops = ["cÃ  chua", "cÃ  phÃª", "lÃºa", "ngÃ´", "á»›t", "dÆ°a háº¥u", "sáº§u riÃªng"]
    areas = ["ruá»™ng A", "vÆ°á»n sá»‘ 5", "nhÃ  kÃ­nh 1", "khu B"]
    activities = ["tÆ°á»›i", "bÃ³n phÃ¢n", "phun thuá»‘c", "thu hoáº¡ch"]
    dates = ["hÃ´m nay", "ngÃ y mai", "tuáº§n nÃ y", "thÃ¡ng nÃ y"]
    
    for _ in range(num_samples):
        # Random simple template
        template = random.choice([
            "cÃ¡ch trá»“ng {crop}",
            "{crop} táº¡i {area}",
            "chÄƒm sÃ³c {crop} á»Ÿ {area}",
            "{activity} {crop} vÃ o {date}",
        ])
        
        # Fill template
        text = template
        entities = []
        
        if "{crop}" in template:
            crop = random.choice(crops)
            start = text.find("{crop}")
            text = text.replace("{crop}", crop)
            entities.append({
                "type": "CROP_NAME",
                "value": crop,
                "start": start,
                "end": start + len(crop)
            })
        
        if "{area}" in template:
            area = random.choice(areas)
            start = text.find("{area}")
            text = text.replace("{area}", area)
            entities.append({
                "type": "AREA",
                "value": area,
                "start": start,
                "end": start + len(area)
            })
        
        if "{activity}" in template:
            activity = random.choice(activities)
            start = text.find("{activity}")
            text = text.replace("{activity}", activity)
            entities.append({
                "type": "ACTIVITY",
                "value": activity,
                "start": start,
                "end": start + len(activity)
            })
        
        if "{date}" in template:
            date = random.choice(dates)
            start = text.find("{date}")
            text = text.replace("{date}", date)
            entities.append({
                "type": "DATE",
                "value": date,
                "start": start,
                "end": start + len(date)
            })
        
        generated.append({
            'text': text,
            'entities': json.dumps(entities, ensure_ascii=False)
        })
    
    return generated


def augment_data(df, num_augmented=500):
    """Main augmentation function"""
    augmented_examples = []
    
    print("ğŸ”„ Applying synonym replacement...")
    for idx, row in df.iterrows():
        # Apply crop synonyms
        crop_augs = synonym_replacement(
            row['text'], 
            row['entities'], 
            CROP_SYNONYMS
        )
        augmented_examples.extend(crop_augs[:2])  # Max 2 per example
        
        # Apply area synonyms
        area_augs = synonym_replacement(
            row['text'], 
            row['entities'], 
            AREA_SYNONYMS
        )
        augmented_examples.extend(area_augs[:2])
        
        if len(augmented_examples) >= num_augmented // 2:
            break
    
    print(f"âœ… Generated {len(augmented_examples)} synonym-based examples")
    
    # Generate from templates
    print("ğŸ² Generating from templates...")
    template_examples = generate_from_templates(num_augmented // 2)
    print(f"âœ… Generated {len(template_examples)} template-based examples")
    
    # Combine
    all_augmented = augmented_examples + template_examples
    
    # Remove duplicates
    seen = set()
    unique_augmented = []
    for ex in all_augmented:
        if ex['text'] not in seen:
            seen.add(ex['text'])
            unique_augmented.append(ex)
    
    print(f"ğŸ“¦ Total unique augmented examples: {len(unique_augmented)}")
    return unique_augmented[:num_augmented]


def main():
    print("=" * 60)
    print("ğŸ“Š NER Data Augmentation")
    print("=" * 60)
    
    # Load original data
    df = load_original_data()
    
    # Augment
    augmented = augment_data(df, num_augmented=500)
    
    # Create augmented dataframe
    aug_df = pd.DataFrame(augmented)
    
    # Combine with original
    combined_df = pd.concat([df, aug_df], ignore_index=True)
    
    # Save
    output_path = Path(__file__).parent.parent / "data" / "ner_data_augmented.csv"
    combined_df.to_csv(output_path, index=False, encoding='utf-8')
    
    print(f"\nâœ… Saved augmented data to: {output_path}")
    print(f"ğŸ“Š Original examples: {len(df)}")
    print(f"ğŸ“Š Augmented examples: {len(aug_df)}")
    print(f"ğŸ“Š Total examples: {len(combined_df)}")
    print("\nğŸ’¡ Next step: Use ner_data_augmented.csv for training!")


if __name__ == "__main__":
    main()
