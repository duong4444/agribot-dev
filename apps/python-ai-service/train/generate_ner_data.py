"""
Script t·ª± ƒë·ªông sinh d·ªØ li·ªáu training cho NER (Named Entity Recognition)
Domain: Smart Agriculture / N√¥ng nghi·ªáp th√¥ng minh

Entity Types: (Gi·ªØ nguy√™n 14 types)
- CROP_NAME, DEVICE, SENSOR_TYPE, METRIC_VALUE, DATE, MONEY,
- DURATION, AREA, QUANTITY, ACTIVITY, FERTILIZER, PESTICIDE,
- TECHNIQUE, SEASON

Improvements (ƒê√£ t·ªëi ∆∞u):
- (M·ªöI) Context-aware generation: C√°c template chuy√™n bi·ªát (v√≠ d·ª•: 
  {SENSOR_TYPE_TEMP} ƒëi v·ªõi {METRIC_VALUE_TEMP}) ƒë·ªÉ ƒë·∫£m b·∫£o
  d·ªØ li·ªáu sinh ra logic (v√≠ d·ª•: "nhi·ªát ƒë·ªô l√† 30¬∞C" thay v√¨ "nhi·ªát ƒë·ªô l√† 6.5pH").
- (M·ªöI) Smart Augmentation: Th√™m h√†m `augment_sample` ƒë·ªÉ
  thay th·∫ø ng·∫´u nhi√™n c√°c th·ª±c th·ªÉ trong c√¢u (v√≠ d·ª•: "b√≥n NPK cho l√∫a" -> "b√≥n DAP cho ng√¥")
  ƒë·ªÉ tƒÉng ƒë·ªô ƒëa d·∫°ng.
- (T·ªêI ∆ØU) Entity Database Cleanup: Lo·∫°i b·ªè s·ª± tr√πng l·∫∑p v√† m∆° h·ªì
  gi·ªØa c√°c lo·∫°i th·ª±c th·ªÉ (v√≠ d·ª•: `DEVICE` vs `SENSOR_TYPE`,
  `ACTIVITY` vs `TECHNIQUE`).
- (M·ªöI) Th√™m templates cho c√°c entity b·ªã thi·∫øu (v√≠ d·ª•: {MONEY}).
- (T·ªêI ∆ØU) T·ªëi ∆∞u h√≥a hi·ªáu su·∫•t b·∫±ng c√°ch bi√™n d·ªãch template m·ªôt l·∫ßn.
- (T·ªêI ∆ØU) C·∫£i thi·ªán logic validation v√† de-duplication.
"""

import csv
import json
import random
import re
import logging
import argparse
from typing import List, Dict, Tuple, Set, Optional, Any
from collections import defaultdict, Counter
from pathlib import Path
from dataclasses import dataclass, field
from tqdm import tqdm
import time

# ============================================================================
# CONFIGURATION
# ============================================================================

@dataclass
class Config:
    """Configuration for NER data generation"""
    input_file: str = "data/ner_data.csv"
    output_file: str = "data/ner_data_augmented.csv"
    target_samples: int = 2000  # TƒÉng target l√™n
    random_seed: int = 42
    log_level: str = "INFO"
    augment_ratio: float = 0.4 # 40% m·∫´u m·ªõi sinh ra s·∫Ω ƒë∆∞·ª£c augment
    min_text_len: int = 5
    max_text_len: int = 250


# ============================================================================
# LOGGING SETUP
# ============================================================================

def setup_logging(level: str = "INFO"):
    """Setup logging configuration"""
    logging.basicConfig(
        level=getattr(logging, level.upper()),
        format='%(asctime)s - %(levelname)s - %(message)s',
        datefmt='%Y-m-%d %H:%M:%S'
    )
    return logging.getLogger(__name__)


logger = setup_logging()


# ============================================================================
# ENTITY DATABASES (ƒê√É T·ªêI ∆ØU V√Ä PH√ÇN LO·∫†I)
# ============================================================================

def get_entity_data():
    """
    Tr·∫£ v·ªÅ database c√°c th·ª±c th·ªÉ.
    (T·ªêI ∆ØU) Ph√¢n lo·∫°i SENSOR_TYPE v√† lo·∫°i b·ªè tr√πng l·∫∑p.
    """
    
    ENTITY_DATA = {
        "CROP_NAME": [
        "l√∫a", "l√∫a n∆∞·ªõc", "l√∫a ST24", "l√∫a ST25", "l√∫a OM 5451", "l√∫a IR 50404", 
        "l√∫a n·∫øp", "l√∫a n·∫øp c√°i hoa v√†ng", "l√∫a c·∫©m", "l√∫a t·∫ª",
        "ng√¥", "ng√¥ n·∫øp", "ng√¥ ng·ªçt", "ng√¥ lai", "ng√¥ NK7328", "ng√¥ t√≠m",
        "khoai lang", "khoai lang k√©n", "khoai lang m·∫≠t", "khoai lang t√≠m Nh·∫≠t",
        "s·∫Øn", "khoai m√¨", "khoai t√¢y", "khoai m·ª°", "khoai s·ªç", "khoai m√¥n",
        "c√† ph√™", "c√† ph√™ Robusta", "c√† ph√™ Arabica", "c√† ph√™ ch√®", "c√† ph√™ v·ªëi",
        "h·ªì ti√™u", "ti√™u ƒëen", "ti√™u s·ªç",
        "cao su", "ƒëi·ªÅu", "h·∫°t ƒëi·ªÅu", "ch√®", "ch√® Th√°i Nguy√™n", "ch√® Shan Tuy·∫øt", "ch√® √î Long",
        "m√≠a", "m√≠a ƒë∆∞·ªùng", "d·ª´a", "d·ª´a xi√™m", "d·ª´a s√°p", "cacao", "thu·ªëc l√°",
        "b√¥ng", "c√¢y b√¥ng v·∫£i", "d√¢u t·∫±m", "ƒë·∫≠u t∆∞∆°ng", "l·∫°c", "ƒë·∫≠u ph·ªông", "v·ª´ng", "m√®",
        "cam", "cam s√†nh", "cam Vinh", "cam canh", "cam Cao Phong",
        "b∆∞·ªüi", "b∆∞·ªüi da xanh", "b∆∞·ªüi Di·ªÖn", "b∆∞·ªüi NƒÉm Roi", "b∆∞·ªüi Ph√∫c Tr·∫°ch",
        "chanh", "chanh kh√¥ng h·∫°t", "chanh leo", "chanh d√¢y", "qu√Ωt", "qu√Ωt ƒë∆∞·ªùng", "t·∫Øc", "qu·∫•t",
        "xo√†i", "xo√†i C√°t H√≤a L·ªôc", "xo√†i ƒê√†i Loan", "xo√†i c√°t chu", "xo√†i t·ª© qu√Ω",
        "s·∫ßu ri√™ng", "s·∫ßu ri√™ng Ri6", "s·∫ßu ri√™ng Musang King", "s·∫ßu ri√™ng Monthong",
        "m√≠t", "m√≠t Th√°i", "m√≠t t·ªë n·ªØ", "m√≠t ru·ªôt ƒë·ªè",
        "nh√£n", "nh√£n l·ªìng", "nh√£n l·ªìng H∆∞ng Y√™n", "nh√£n xu·ªìng c∆°m v√†ng", "nh√£n Ido",
        "v·∫£i", "v·∫£i thi·ªÅu", "v·∫£i thi·ªÅu L·ª•c Ng·∫°n", "v·∫£i u tr·ª©ng",
        "thanh long", "thanh long ru·ªôt ƒë·ªè", "thanh long ru·ªôt tr·∫Øng", "thanh long B√¨nh Thu·∫≠n",
        "chu·ªëi", "chu·ªëi ti√™u", "chu·ªëi t√¢y", "chu·ªëi ng·ª±", "chu·ªëi cau", "chu·ªëi Laba",
        "ƒëu ƒë·ªß", "d·ª©a", "th∆°m", "kh√≥m", "ch√¥m ch√¥m", "ch√¥m ch√¥m nh√£n", "ch√¥m ch√¥m Th√°i",
        "mƒÉng c·ª•t", "v√∫ s·ªØa", "v√∫ s·ªØa L√≤ R√®n", "b∆°", "b∆° 034", "b∆° s√°p", "b∆° booth",
        "na", "m√£ng c·∫ßu", "m√£ng c·∫ßu xi√™m", "d√¢u t√¢y", "d√¢u t·∫±m", "d∆∞a h·∫•u", "d∆∞a h·∫•u H·∫Øc M·ªπ Nh√¢n",
        "d∆∞a l∆∞·ªõi", "d∆∞a l√™", "·ªïi", "·ªïi N·ªØ Ho√†ng", "·ªïi l√™", "m·∫≠n", "m·∫≠n h·∫≠u", "roi", "h·ªìng xi√™m", "sapoche",
        "rau c·∫£i", "c·∫£i ng·ªçt", "c·∫£i th√¨a", "c·∫£i b·∫π xanh", "c·∫£i c√∫c", "t·∫ßn √¥",
        "b·∫Øp c·∫£i", "c·∫£i th·∫£o", "c·∫£i b√≥ x√¥i", "rau mu·ªëng", "rau d·ªÅn", "rau ng√≥t",
        "m·ªìng t∆°i", "x√† l√°ch", "x√† l√°ch m·ª°", "x√† l√°ch xoong", "c·∫ßn t√¢y", "rau m√°",
        "c√† chua", "c√† chua bi", "c√† chua cherry", "c√† t√≠m", "c√† ph√°o",
        "d∆∞a chu·ªôt", "d∆∞a leo", "b√≠ ƒëao", "b√≠ xanh", "b√≠ ƒë·ªè", "b√≠ ng√¥",
        "b·∫ßu", "m∆∞·ªõp", "m∆∞·ªõp ƒë·∫Øng", "kh·ªï qua", "su su", "ƒë·∫≠u b·∫Øp",
        "·ªõt", "·ªõt chu√¥ng", "·ªõt hi·ªÉm", "·ªõt s·ª´ng",
        "su h√†o", "c·ªß c·∫£i", "c√† r·ªët", "c·ªß d·ªÅn",
        "ƒë·∫≠u", "ƒë·∫≠u c√¥ ve", "ƒë·∫≠u ƒë≈©a", "ƒë·∫≠u H√† Lan",
        "s√∫p l∆°", "b√¥ng c·∫£i xanh", "b√¥ng c·∫£i tr·∫Øng", "mƒÉng t√¢y",
        "h√†nh l√°", "h√†nh t√¢y", "h√†nh t√≠m", "t·ªèi", "t·ªèi L√Ω S∆°n", "t·ªèi c√¥ ƒë∆°n",
        "g·ª´ng", "ngh·ªá", "ri·ªÅng", "s·∫£", "rau m√πi", "ng√≤ r√≠", "rau rƒÉm",
        "t√≠a t√¥", "kinh gi·ªõi", "h√∫ng qu·∫ø", "h√∫ng chanh", "th√¨ l√†", "l√° l·ªët",
        "hoa h·ªìng", "hoa lan", "hoa c√∫c", "hoa ly", "hoa hu·ªá", "hoa ƒë·ªìng ti·ªÅn",
        "hoa lay ∆°n", "hoa sen", "hoa s√∫ng", "hoa ƒë√†o", "hoa mai",
        "n·∫•m", "n·∫•m r∆°m", "n·∫•m b√†o ng∆∞", "n·∫•m h∆∞∆°ng", "n·∫•m kim ch√¢m",
        "n·∫•m m·ª°", "n·∫•m ƒë√πi g√†", "m·ªôc nhƒ©", "n·∫•m linh chi"
        ],
        "DEVICE": [
            "m√°y b∆°m", "m√°y b∆°m 1", "b∆°m ch√¨m", "qu·∫°t th√¥ng gi√≥", "qu·∫°t ƒë·ªëi l∆∞u",
            "ƒë√®n LED", "ƒë√®n UV", "ƒë√®n s∆∞·ªüi", "van n∆∞·ªõc", "van ƒëi·ªán t·ª´", "van s·ªë 1",
            "h·ªá th·ªëng t∆∞·ªõi", "h·ªá th·ªëng t∆∞·ªõi t·ª± ƒë·ªông", "h·ªá th·ªëng t∆∞·ªõi nh·ªè gi·ªçt",
            "c·∫£m bi·∫øn",
            "drone", "m√°y c√†y", "m√°y g·∫∑t", "m√°y phun thu·ªëc", "nh√† l∆∞·ªõi", "nh√† m√†ng",
            "nh√† k√≠nh", "camera gi√°m s√°t", "tr·∫°m th·ªùi ti·∫øt", "r∆° le", "b·ªô ƒëi·ªÅu khi·ªÉn",
            "m√°y s·∫•y", "m√°y s∆∞·ªüi", "m√°y phun s∆∞∆°ng", "h·ªá th·ªëng ch√¢m ph√¢n",
            "r√®m che", "l∆∞·ªõi c·∫Øt n·∫Øng",
        ],

        "SENSOR_TYPE_TEMP": ["nhi·ªát ƒë·ªô", "nhi·ªát ƒë·ªô kh√¥ng kh√≠", "nhi·ªát ƒë·ªô ƒë·∫•t", "nhi·ªát ƒë·ªô n∆∞·ªõc"],
        "SENSOR_TYPE_HUMID": ["ƒë·ªô ·∫©m", "ƒë·ªô ·∫©m kh√¥ng kh√≠", "ƒë·ªô ·∫©m ƒë·∫•t"],
        "SENSOR_TYPE_LIGHT": ["√°nh s√°ng", "c∆∞·ªùng ƒë·ªô √°nh s√°ng", "lux", "PAR", "b·ª©c x·∫°"],
        "SENSOR_TYPE_PH": ["pH", "pH ƒë·∫•t", "pH n∆∞·ªõc"],
        "SENSOR_TYPE_EC": ["EC", "ƒë·ªô d·∫´n ƒëi·ªán", "EC n∆∞·ªõc", "EC ƒë·∫•t"],
        "SENSOR_TYPE_CO2": ["CO2", "n·ªìng ƒë·ªô CO2"],
        "SENSOR_TYPE_WIND": ["t·ªëc ƒë·ªô gi√≥", "h∆∞·ªõng gi√≥"],
        "SENSOR_TYPE_RAIN": ["l∆∞·ª£ng m∆∞a", "c·∫£m bi·∫øn m∆∞a"],
        "SENSOR_TYPE_WATER": ["m·ª±c n∆∞·ªõc", "oxy h√≤a tan", "ƒë·ªô m·∫∑n", "ƒë·ªô ƒë·ª•c"],
        "ACTIVITY": [
            "t∆∞·ªõi n∆∞·ªõc", "t∆∞·ªõi c√¢y", "b√≥n ph√¢n", "b√≥n l√≥t", "b√≥n th√∫c", "b√≥n v√¥i",
            "thu ho·∫°ch", "gieo h·∫°t", "gieo m·∫°", "phun thu·ªëc", "l√†m c·ªè", "nh·ªï c·ªè",
            "x·ªõi ƒë·∫•t", "c√†y ƒë·∫•t", "l√†m ƒë·∫•t", "t·ªâa c√†nh", "c·∫Øt t·ªâa", "l√™n lu·ªëng",
            "·ªß ph√¢n", "c·∫•y l√∫a", "tr·ªìng c√¢y", "gh√©p c√†nh", "chi·∫øt c√†nh", "b·∫Øt s√¢u",
            "d·ªçn v∆∞·ªùn", "s·ª≠a ch·ªØa", "b·∫£o tr√¨", "th·ª• ph·∫•n", "chƒÉm s√≥c", "ki·ªÉm tra",
        ],
        
        "FERTILIZER": [
            "ph√¢n b√≥n", "ph√¢n NPK", "NPK 16-16-8", "NPK 20-20-15", "ph√¢n ƒë·∫°m",
            "ph√¢n Ure", "ph√¢n l√¢n", "Super L√¢n", "DAP", "ph√¢n kali", "ph√¢n KCL",
            "ph√¢n h·ªØu c∆°", "ph√¢n compost", "ph√¢n chu·ªìng", "ph√¢n tr√πn qu·∫ø",
            "ph√¢n vi sinh", "v√¥i b·ªôt", "ph√¢n b√≥n l√°", "ph√¢n g√†", "dung d·ªãch th·ªßy canh",
            "Canxi nitrat", "Magie Sunfat", "ph√¢n vi l∆∞·ª£ng",
        ],
        
        "PESTICIDE": [
            "s√¢u ƒë·ª•c th√¢n", "s√¢u cu·ªën l√°", "r·ªáp s√°p", "r·∫ßy n√¢u", "b·ªç trƒ©",
            "b·ªç ph·∫•n tr·∫Øng", "nh·ªán ƒë·ªè", "ru·ªìi v√†ng", "·ªëc b∆∞∆°u v√†ng", "chu·ªôt",
            "b·ªánh ƒë·∫°o √¥n", "b·ªánh r·ªâ s·∫Øt", "b·ªánh h√©o xanh", "b·ªánh th√°n th∆∞",
            "b·ªánh xoƒÉn l√°", "b·ªánh ƒë·ªëm l√°", "b·ªánh th·ªëi r·ªÖ", "b·ªánh Greening",
            "b·ªánh ph·∫•n tr·∫Øng", "thu·ªëc tr·ª´ s√¢u", "thu·ªëc di·ªát c·ªè", "thu·ªëc tr·ª´ b·ªánh",
            "thu·ªëc sinh h·ªçc", "Regent", "Confidor", "Anvil", "Ridomil Gold",
            "Amistar Top", "d·∫ßu kho√°ng", "b·∫£ chu·ªôt", "b·∫´y Pheromone",
        ],
        
        "TECHNIQUE": [
            "th·ªßy canh", "th·ªßy canh NFT", "aquaponics", "kh√≠ canh",
            "tr·ªìng xen canh", "tr·ªìng lu√¢n canh", "t∆∞·ªõi nh·ªè gi·ªçt", "t∆∞·ªõi phun s∆∞∆°ng",
            "canh t√°c h·ªØu c∆°", "tr·ªìng rau s·∫°ch", "VietGAP", "GlobalGAP", "IPM",
            "gh√©p c√†nh", "chi·∫øt c√†nh", "nh√¢n gi·ªëng v√¥ t√≠nh", "·ªß ph√¢n compost",
            "tr·ªìng trong nh√† m√†ng", "nu√¥i c·∫•y m√¥", "nu√¥i tr√πn qu·∫ø", "che ph·ªß nilon",
            "gieo s·∫° h√†ng", "canh t√°c kh√¥ng d√πng ƒë·∫•t",
        ],
        
        "SEASON": [
            "m√πa xu√¢n", "m√πa h·∫°", "m√πa thu", "m√πa ƒë√¥ng", "m√πa m∆∞a", "m√πa kh√¥",
            "v·ª• m√πa", "v·ª• chi√™m", "v·ª• h√® thu", "v·ª• ƒë√¥ng xu√¢n", "v·ª• s·ªõm", "v·ª• mu·ªôn",
            "v·ª• T·∫øt", "v·ª• 1", "v·ª• 2", "ƒë·∫ßu m√πa", "cu·ªëi m√πa",
        ],
        
        "AREA": [
            "khu A", "khu B", "lu·ªëng 1", "lu·ªëng A1", "v∆∞·ªùn cam", "v∆∞·ªùn ∆∞∆°m",
            "nh√† m√†ng s·ªë 1", "nh√† k√≠nh 2", "kho l·∫°nh", "kho v·∫≠t t∆∞", "h·ªì ch·ª©a B",
            "khu th·ª≠ nghi·ªám", "ƒë·ªìng ru·ªông",
        ],
    }

    # (M·ªöI) T·∫°o SENSOR_TYPE t·ªïng h·ª£p t·ª´ c√°c lo·∫°i con
    all_sensors = []
    for k, v in ENTITY_DATA.items():
        if k.startswith("SENSOR_TYPE_"):
            all_sensors.extend(v)
    ENTITY_DATA["SENSOR_TYPE"] = list(set(all_sensors))
    
    return ENTITY_DATA

ENTITY_DATA = get_entity_data()

# ============================================================================
# TEMPLATE GENERATION (ƒê√É C·∫¢I TI·∫æN V·ªöI CONTEXT-AWARE)
# ============================================================================

TEMPLATES = {
    # Templates ƒë∆°n gi·∫£n
    "CROP_queries": [
        "c√°ch tr·ªìng {CROP_NAME}",
        "k·ªπ thu·∫≠t chƒÉm s√≥c {CROP_NAME}",
        "{CROP_NAME} b·ªã {PESTICIDE}",
        "thu ho·∫°ch {CROP_NAME} {SEASON}",
        "gi·ªëng {CROP_NAME} n√†y t·ªët kh√¥ng",
        "{CROP_NAME} b·ªã v√†ng l√°",
    ],
    "DEVICE_control": [
        "b·∫≠t {DEVICE}",
        "t·∫Øt {DEVICE}",
        "ki·ªÉm tra {DEVICE} ·ªü {AREA}",
        "s·ª≠a ch·ªØa {DEVICE}",
        "l·∫Øp ƒë·∫∑t {DEVICE} cho {AREA}",
        "tr·∫°ng th√°i {DEVICE}",
    ],
    "SENSOR_queries": [
        "ki·ªÉm tra {SENSOR_TYPE}",
        "xem {SENSOR_TYPE} ·ªü {AREA}",
        "{SENSOR_TYPE} hi·ªán t·∫°i l√† bao nhi√™u",
        "gi√° tr·ªã {SENSOR_TYPE}",
    ],
    
    # (M·ªöI) Templates nh·∫≠n bi·∫øt ng·ªØ c·∫£nh
    "SENSOR_CONTEXT_AWARE": [
        "{SENSOR_TYPE_TEMP} ·ªü {AREA} l√† {METRIC_VALUE_TEMP}",
        "{AREA} c√≥ {SENSOR_TYPE_HUMID} {METRIC_VALUE_HUMID}",
        "ƒëo {SENSOR_TYPE_PH} t·∫°i {AREA} ƒë∆∞·ª£c {METRIC_VALUE_PH}",
        "{SENSOR_TYPE_EC} c·ªßa {AREA} l√† {METRIC_VALUE_EC}",
        "ki·ªÉm tra {SENSOR_TYPE_LIGHT} ·ªü {AREA}, ƒëang l√† {METRIC_VALUE_LIGHT}",
        "{SENSOR_TYPE_CO2} trong {AREA} ƒë·∫°t {METRIC_VALUE_CO2}",
        "{SENSOR_TYPE_WIND} h√¥m nay {METRIC_VALUE_WIND}",
        "{SENSOR_TYPE_RAIN} ƒëo ƒë∆∞·ª£c {METRIC_VALUE_RAIN}",
        "{SENSOR_TYPE_WATER} trong h·ªì l√† {METRIC_VALUE_WATER}",
    ],

    # (M·ªöI) Templates t√†i ch√≠nh
    "FINANCE_QUERIES": [
        "mua {QUANTITY} {FERTILIZER} h·∫øt {MONEY}",
        "chi ph√≠ {ACTIVITY} l√† {MONEY}",
        "thu {MONEY} t·ª´ {CROP_NAME} t·∫°i {AREA}",
        "gi√° {QUANTITY} {CROP_NAME} l√† {MONEY}",
        "tr·∫£ {MONEY} ti·ªÅn {PESTICIDE}",
        "l·ª£i nhu·∫≠n {SEASON} l√† {MONEY}",
    ],

    # Templates ph·ª©c h·ª£p (Nhi·ªÅu entities)
    "COMPLEX_ACTIONS": [
        "{ACTIVITY} {CROP_NAME} ·ªü {AREA}",
        "{ACTIVITY} cho {CROP_NAME} t·∫°i {AREA} v√†o {DATE}",
        "c·∫ßn {ACTIVITY} {CROP_NAME} {AREA}",
        "thu ho·∫°ch {QUANTITY} {CROP_NAME} ·ªü {AREA}",
        "{AREA} thu ƒë∆∞·ª£c {QUANTITY} {CROP_NAME} {SEASON}",
        "tr·ªìng {QUANTITY} {CROP_NAME} t·∫°i {AREA}",
        "b·∫≠t {DEVICE} ·ªü {AREA} trong {DURATION}",
        "t∆∞·ªõi {QUANTITY} n∆∞·ªõc cho {AREA} l√∫c {DATE}",
        "b√≥n {QUANTITY} {FERTILIZER} cho {CROP_NAME} ·ªü {AREA}",
        "{CROP_NAME} t·∫°i {AREA} b·ªã {PESTICIDE}",
        "phun {PESTICIDE} cho {CROP_NAME} v√†o {DATE}",
        "√°p d·ª•ng {TECHNIQUE} tr·ªìng {CROP_NAME} t·∫°i {AREA}",
        "ghi nh·∫≠n {ACTIVITY} t·∫°i {AREA} l√∫c {DATE}",
        "c·∫ßn {QUANTITY} {FERTILIZER} cho {CROP_NAME} {SEASON}",
    ],
}


# ============================================================================
# VALUE GENERATION (ƒê√É PH√ÇN LO·∫†I)
# ============================================================================

# (M·ªöI) C√°c h√†m generate theo ng·ªØ c·∫£nh
def generate_temp_value(): return f"{random.choice([f'{random.randint(15, 40)}', f'{round(random.uniform(15, 40), 1)}'])}¬∞C"
def generate_humid_value(): return f"{random.randint(40, 100)}%"
def generate_ph_value(): return f"{round(random.uniform(4.0, 9.0), 1)}"
def generate_ec_value(): return f"{round(random.uniform(0.5, 3.5), 1)} mS/cm"
def generate_light_value(): return f"{random.randint(100, 50000)} lux"
def generate_co2_value(): return f"{random.randint(300, 2000)} ppm"
def generate_wind_value(): return f"{round(random.uniform(0, 20), 1)} m/s"
def generate_rain_value(): return f"{random.randint(0, 100)} mm"
def generate_water_value(): return f"{round(random.uniform(1, 10), 1)} mg/L"

def generate_date() -> str:
    dates = [
        "h√¥m nay", "ng√†y mai", "h√¥m qua", "s√°ng nay", "chi·ªÅu nay", "t·ªëi qua",
        "th·ª© hai", "tu·∫ßn tr∆∞·ªõc", "th√°ng n√†y", "th√°ng 10", f"th√°ng {random.randint(1,12)}",
        "15/10", f"{random.randint(1,30)}/{random.randint(1,12)}",
        f"{random.randint(1,30)}-{random.randint(1,12)}-2024",
        f"{random.randint(5,18)}h", f"{random.randint(8,17)}:30",
        "qu√Ω 1", "cu·ªëi nƒÉm",
    ]
    return random.choice(dates)

def generate_money() -> str:
    money_types = [
        lambda: f"{random.randint(10, 500)}k",
        lambda: f"{random.randint(1, 100)} tri·ªáu",
        lambda: f"{random.randint(1, 10)} t·ª∑",
        lambda: f"{random.randint(10, 1000)} ngh√¨n ƒë·ªìng",
        lambda: f"{random.choice([1.5, 2.5, 3.5])} tri·ªáu",
        lambda: f"{random.randint(100, 999)}.000 VNƒê",
        lambda: f"{random.randint(10, 999)}.000ƒë",
    ]
    return random.choice(money_types)()

def generate_duration() -> str:
    durations = [
        f"{random.randint(5, 60)} ph√∫t",
        f"{random.randint(1, 12)} gi·ªù",
        f"{random.randint(1, 7)} ng√†y",
        f"{random.randint(1, 4)} tu·∫ßn",
        f"{random.randint(1, 6)} th√°ng",
        "n·ª≠a ti·∫øng", "c·∫£ ng√†y", "1 ti·∫øng r∆∞·ª°i",
    ]
    return random.choice(durations)

def generate_quantity() -> str:
    quantities = [
        f"{random.randint(1, 500)}kg",
        f"{random.randint(1, 100)} l√≠t",
        f"{random.randint(1, 5)} t·∫•n",
        f"{random.randint(1, 100)} c√¢y",
        f"{random.randint(1, 20)} bao",
        f"{random.randint(1, 10)} t·∫°",
        f"{random.randint(1, 10)} ha", # hecta
        f"{random.randint(100, 5000)} m2",
        f"{random.choice([1.5, 0.5, 2.5])} t·∫•n",
        f"{random.randint(100, 999)}g",
        f"{random.randint(10, 999)}ml",
    ]
    return random.choice(quantities)

# (C·∫¢I TI·∫æN) Map c√°c generator theo ng·ªØ c·∫£nh
DYNAMIC_GENERATORS = {
    # Context-aware
    "METRIC_VALUE_TEMP": generate_temp_value,
    "METRIC_VALUE_HUMID": generate_humid_value,
    "METRIC_VALUE_PH": generate_ph_value,
    "METRIC_VALUE_EC": generate_ec_value,
    "METRIC_VALUE_LIGHT": generate_light_value,
    "METRIC_VALUE_CO2": generate_co2_value,
    "METRIC_VALUE_WIND": generate_wind_value,
    "METRIC_VALUE_RAIN": generate_rain_value,
    "METRIC_VALUE_WATER": generate_water_value,
    
    # Generic (D√πng cho c√°c template c≈© n·∫øu c·∫ßn)
    "METRIC_VALUE": lambda: random.choice([
        generate_temp_value(), generate_humid_value(), generate_ph_value(),
        generate_ec_value(), generate_light_value(), generate_co2_value()
    ])(),
    
    # Standard dynamic
    "DATE": generate_date,
    "MONEY": generate_money,
    "DURATION": generate_duration,
    "QUANTITY": generate_quantity,
}


# ============================================================================
# NER DATA GENERATION (ƒê√É T·ªêI ∆ØU)
# ============================================================================

@dataclass
class NerSample:
    """Class ƒë·ªÉ l∆∞u tr·ªØ m·ªôt m·∫´u NER ƒë√£ sinh ra"""
    text: str
    entities: List[Dict[str, Any]] = field(default_factory=list)
    
    def to_tuple(self) -> Tuple[str, List[Dict]]:
        return (self.text, self.entities)

    def to_csv_row(self) -> Tuple[str, str]:
        return (self.text, json.dumps(self.entities, ensure_ascii=False))


class NERDataGenerator:
    """Generate NER training data"""
    
    def __init__(self, config: Config):
        self.config = config
        random.seed(config.random_seed)
        self.generated_texts: Set[str] = set() # D√πng ƒë·ªÉ de-duplicate
        
        # (T·ªêI ∆ØU) Bi√™n d·ªãch template list m·ªôt l·∫ßn
        self.template_list = [
            template
            for category, templates in TEMPLATES.items()
            for template in templates
        ]
        logger.info(f"Compiled {len(self.template_list)} templates.")

    def is_valid(self, sample: NerSample) -> bool:
        """Ki·ªÉm tra xem sample c√≥ h·ª£p l·ªá kh√¥ng"""
        if not sample.text or not sample.entities:
            return False
        if not (self.config.min_text_len <= len(sample.text) <= self.config.max_text_len):
            return False
        
        # Ki·ªÉm tra de-duplicate
        normalized_text = sample.text.lower()
        if normalized_text in self.generated_texts:
            return False
            
        # (M·ªöI) Ki·ªÉm tra entity c√≥ kh·ªõp kh√¥ng (validation)
        for ent in sample.entities:
            start, end = ent['start'], ent['end']
            if sample.text[start:end] != ent['value']:
                logger.warning(f"Entity mismatch: text='{sample.text[start:end]}', value='{ent['value']}'")
                return False
        
        self.generated_texts.add(normalized_text)
        return True

    def fill_template(self, template: str) -> Optional[NerSample]:
        """
        Fill template v·ªõi entities v√† tr·∫£ v·ªÅ text + entity list.
        Logic offset c·ªßa user ƒë√£ ch√≠nh x√°c, gi·ªØ nguy√™n.
        """
        text = template
        entities = []
        offset = 0
        
        # T√¨m t·∫•t c·∫£ placeholders m·ªôt c√°ch an to√†n
        matches = list(re.finditer(r'\{(\w+)\}', template))
        if not matches:
            return None
        
        for match in matches:
            entity_type = match.group(1)
            placeholder = match.group(0)
            
            # Get value
            if entity_type in DYNAMIC_GENERATORS:
                value = DYNAMIC_GENERATORS[entity_type]()
            elif entity_type in ENTITY_DATA:
                value = random.choice(ENTITY_DATA[entity_type])
            else:
                logger.warning(f"Unknown entity type in template: {entity_type}")
                continue
            
            # Calculate position in final text
            start = match.start() + offset
            end = start + len(value)
            
            # Replace in text
            text = text[:start] + value + text[match.end() + offset:]
            
            # Update offset
            offset += len(value) - len(placeholder)
            
            # Add entity
            entities.append({
                "type": entity_type,
                "value": value,
                "start": start,
                "end": end
            })
        
        return NerSample(text, entities)

    
    def augment_sample(self, sample: NerSample) -> Optional[NerSample]:
        """
        (M·ªöI) Augment m·ªôt sample b·∫±ng c√°ch thay th·∫ø m·ªôt entity.
        V√≠ d·ª•: "b√≥n NPK cho l√∫a" -> "b√≥n DAP cho ng√¥"
        """
        if not sample.entities:
            return None
        
        # 1. Ch·ªçn m·ªôt entity ƒë·ªÉ thay th·∫ø
        ent_to_replace = random.choice(sample.entities)
        ent_type = ent_to_replace['type']
        old_value = ent_to_replace['value']
        
        # 2. L·∫•y gi√° tr·ªã m·ªõi
        # ƒê·∫£m b·∫£o gi√° tr·ªã m·ªõi kh√°c gi√° tr·ªã c≈©
        if ent_type in DYNAMIC_GENERATORS:
            new_value = DYNAMIC_GENERATORS[ent_type]()
            if new_value == old_value: # Th·ª≠ l·∫°i m·ªôt l·∫ßn
                 new_value = DYNAMIC_GENERATORS[ent_type]()
        elif ent_type in ENTITY_DATA:
            new_value = random.choice(ENTITY_DATA[ent_type])
            if new_value == old_value and len(ENTITY_DATA[ent_type]) > 1: # Th·ª≠ l·∫°i
                new_value = random.choice(ENTITY_DATA[ent_type])
        else:
            return None # Kh√¥ng th·ªÉ thay th·∫ø
        
        if new_value == old_value:
            return None # Kh√¥ng t√¨m ƒë∆∞·ª£c gi√° tr·ªã thay th·∫ø
            
        # 3. T·∫°o text m·ªõi
        start_replace = ent_to_replace['start']
        end_replace = ent_to_replace['end']
        new_text = sample.text[:start_replace] + new_value + sample.text[end_replace:]
        
        # 4. T√≠nh to√°n l·∫°i c√°c entity
        new_entities = []
        offset = len(new_value) - len(old_value)
        
        for ent in sample.entities:
            new_ent = ent.copy()
            if ent == ent_to_replace:
                # C·∫≠p nh·∫≠t entity ƒë√£ thay th·∫ø
                new_ent['value'] = new_value
                new_ent['end'] = new_ent['start'] + len(new_value)
            elif ent['start'] > start_replace:
                # C·∫≠p nh·∫≠t c√°c entity ph√≠a sau
                new_ent['start'] += offset
                new_ent['end'] += offset
            
            new_entities.append(new_ent)
            
        return NerSample(new_text, new_entities)

    def generate(self, target_count: int, existing_data: List[Tuple[str, str]] = []) -> List[NerSample]:
        """Main generation method"""
        all_samples: List[NerSample] = []
        
        # 1. Th√™m v√† validate d·ªØ li·ªáu c≈©
        if existing_data:
            logger.info(f"Loading and validating {len(existing_data)} existing samples...")
            for text, entities_json in tqdm(existing_data, desc="Loading existing"):
                try:
                    entities = json.loads(entities_json)
                    sample = NerSample(text, entities)
                    if self.is_valid(sample):
                        all_samples.append(sample)
                except Exception as e:
                    logger.warning(f"Error processing existing sample: {e}")
        
        logger.info(f"Loaded {len(all_samples)} valid existing samples.")

        # 2. Generate
        needed = target_count - len(all_samples)
        if needed <= 0:
            logger.warning(f"Existing data ({len(all_samples)}) already meets target ({target_count}). No new samples generated.")
            return all_samples[:target_count]
            
        logger.info(f"Generating {needed} new samples...")
        
        pbar = tqdm(total=needed, desc="Generating new")
        attempts = 0
        max_attempts = needed * 20 # TƒÉng max attempts
        
        while len(all_samples) < target_count and attempts < max_attempts:
            attempts += 1
            
            # 2a. T·∫°o m·∫´u t·ª´ template
            template = random.choice(self.template_list)
            new_sample = self.fill_template(template)
            
            if new_sample and self.is_valid(new_sample):
                all_samples.append(new_sample)
                pbar.update(1)
                
                # 2b. (M·ªöI) Augment m·∫´u v·ª´a t·∫°o
                if random.random() < self.config.augment_ratio:
                    aug_sample = self.augment_sample(new_sample)
                    if aug_sample and self.is_valid(aug_sample):
                        all_samples.append(aug_sample)
                        # Kh√¥ng update pbar ·ªü ƒë√¢y v√¨ ƒë√¢y l√† m·∫´u bonus
        
        pbar.close()
        
        if attempts >= max_attempts:
            logger.warning(f"Reached max attempts. Generated {len(all_samples)} samples.")
        
        logger.info(f"Total samples (existing + new + augmented): {len(all_samples)}")
        return all_samples


# ============================================================================
# DATA I/O (ƒê√É T·ªêI ∆ØU)
# ============================================================================

def load_existing_data(filepath: str) -> List[Tuple[str, str]]:
    """Load existing NER data (robust)"""
    data = []
    file_path = Path(filepath)
    
    if not file_path.exists():
        logger.warning(f"File {filepath} kh√¥ng t·ªìn t·∫°i. S·∫Ω t·∫°o m·ªõi.")
        return data
    
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            if 'text' not in reader.fieldnames or 'entities' not in reader.fieldnames:
                 logger.error(f"File {filepath} thi·∫øu c·ªôt 'text' ho·∫∑c 'entities'.")
                 return data
                 
            for row_num, row in enumerate(reader, start=2):
                try:
                    text = row.get('text', '').strip()
                    entities_json = row.get('entities', '').strip()
                    
                    if text and entities_json:
                        # Validate JSON format
                        _ = json.loads(entities_json) 
                        data.append((text, entities_json))
                    else:
                        logger.warning(f"B·ªè qua d√≤ng {row_num}: thi·∫øu text ho·∫∑c entities.")
                        
                except json.JSONDecodeError:
                     logger.warning(f"L·ªói JSON ·ªü d√≤ng {row_num}: {entities_json[:50]}...")
                except Exception as e:
                    logger.warning(f"L·ªói ƒë·ªçc d√≤ng {row_num}: {e}")
            
        logger.info(f"Loaded {len(data)} existing samples from {filepath}")
        
    except Exception as e:
        logger.error(f"Error loading file {filepath}: {e}")
    
    return data


def save_ner_data(samples: List[NerSample], output_filepath: str) -> bool:
    """Save NER data to CSV"""
    if not samples:
        logger.error("Kh√¥ng c√≥ m·∫´u n√†o ƒë·ªÉ l∆∞u.")
        return False
        
    try:
        output_path = Path(output_filepath)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        # Shuffle
        random.shuffle(samples)
        
        # Write
        with open(output_filepath, 'w', encoding='utf-8', newline='') as f:
            writer = csv.writer(f)
            writer.writerow(['text', 'entities'])
            
            for sample in samples:
                writer.writerow(sample.to_csv_row())
        
        logger.info(f"‚úÖ Saved {len(samples)} samples to {output_filepath}")
        
        # Statistics
        entity_counts = Counter()
        for sample in samples:
            for entity in sample.entities:
                entity_counts[entity['type']] += 1
        
        logger.info("\nüìä Entity Distribution:")
        for entity_type, count in sorted(entity_counts.items(), key=lambda x: -x[1]):
            logger.info(f"  {entity_type}: {count}")
        
        # Multi-entity stats
        multi_entity_samples = sum(1 for s in samples if len(s.entities) > 1)
        if samples: # Tr√°nh chia cho 0
            logger.info(f"\nüìà Multi-entity samples: {multi_entity_samples} ({multi_entity_samples/len(samples)*100:.1f}%)")
        
        return True
        
    except Exception as e:
        logger.error(f"Error saving file {output_filepath}: {e}")
        return False


# ============================================================================
# MAIN
# ============================================================================

def main():
    """Main function"""
    parser = argparse.ArgumentParser(description="Generate NER training data for smart agriculture")
    parser.add_argument('--input', default="data/ner_data.csv", help="Input CSV file (optional, for loading existing data)")
    parser.add_argument('--output', default="data/ner_data_augmented.csv", help="Output CSV file")
    parser.add_argument('--target', type=int, default=2000, help="Target number of samples")
    parser.add_argument('--seed', type=int, default=42, help="Random seed")
    parser.add_argument('--log-level', default="INFO", choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'])
    
    args = parser.parse_args()
    
    config = Config(
        input_file=args.input,
        output_file=args.output,
        target_samples=args.target,
        random_seed=args.seed,
        log_level=args.log_level
    )
    
    global logger
    logger = setup_logging(config.log_level)
    
    random.seed(config.random_seed)
    
    logger.info("üöÄ Starting NER Data Generation...")
    logger.info(f"Config: {config}")
    
    try:
        start_time = time.time()
        
        # Load existing data
        existing_data = load_existing_data(config.input_file)
        
        # Generate
        generator = NERDataGenerator(config)
        samples = generator.generate(config.target_samples, existing_data)
        
        if not samples:
            logger.error("No samples generated. Exiting.")
            return 1
        
        # Save
        success = save_ner_data(samples, config.output_file)
        
        if not success:
            logger.error("Failed to save data. Exiting.")
            return 1
        
        end_time = time.time()
        logger.info(f"\n‚ú® Done in {end_time - start_time:.2f} seconds!")
        return 0
        
    except KeyboardInterrupt:
        logger.warning("\n‚ö†Ô∏è  Process interrupted by user")
        return 1
    except Exception as e:
        logger.error(f"\n‚ùå Unexpected error: {e}", exc_info=True)
        return 1


if __name__ == "__main__":
    exit(main())