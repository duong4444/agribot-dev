# Chiáº¿n LÆ°á»£c Cáº£i Thiá»‡n NER Performance

## ğŸ“Š Hiá»‡n Táº¡i
- **F1 Score**: ~0.80
- **Precision**: ~0.78
- **Recall**: ~0.82

## ğŸ¯ Má»¥c TiÃªu
- **F1 Score**: 0.90+
- **Precision**: 0.88+
- **Recall**: 0.90+

---

## ğŸš€ Chiáº¿n LÆ°á»£c Cáº£i Thiá»‡n

### 1. **TÄƒng Sá»‘ LÆ°á»£ng Dá»¯ Liá»‡u Training** (Hiá»‡u Quáº£ Nháº¥t â­â­â­â­â­)

**Hiá»‡n táº¡i:** 948 examples
**Khuyáº¿n nghá»‹:** 2000-5000 examples

#### CÃ¡ch thá»±c hiá»‡n:
```python
# ThÃªm dá»¯ liá»‡u vÃ o train/data/ner_data.csv
# Táº­p trung vÃ o cÃ¡c cases model dá»± Ä‘oÃ¡n sai:

# 1. Multi-entity sentences
"bÃ³n 50kg phÃ¢n NPK cho cÃ  chua á»Ÿ ruá»™ng A ngÃ y mai"
â†’ Entities: QUANTITY, FERTILIZER, CROP_NAME, AREA, DATE

# 2. Ambiguous cases
"cÃ " â†’ cÃ³ thá»ƒ lÃ  "cÃ  chua", "cÃ  phÃª", "cÃ  rá»‘t"

# 3. Rare entities
"dÆ°a lÆ°á»›i", "mÄƒng tÃ¢y", "atiso"

# 4. Edge cases
"cÃ¢y cao 1.5m" â†’ 1.5m lÃ  METRIC_VALUE
"giÃ¡ 50k/kg" â†’ 50k lÃ  MONEY
```

**TÃ¡c Ä‘á»™ng:** +5-10% F1 score

---

### 2. **Data Augmentation** (Tá»± Äá»™ng TÄƒng Dá»¯ Liá»‡u) â­â­â­â­

#### Script tá»± Ä‘á»™ng táº¡o thÃªm dá»¯ liá»‡u:

```python
# train/scripts/augment_ner_data.py
import pandas as pd
import random

# Äá»c data hiá»‡n táº¡i
df = pd.read_csv('../data/ner_data.csv')

# Augmentation strategies:

# 1. Synonym replacement
CROP_SYNONYMS = {
    "cÃ  chua": ["cÃ  chua", "quáº£ cÃ  chua", "cÃ¢y cÃ  chua"],
    "lÃºa": ["lÃºa", "thÃ³c", "cÃ¢y lÃºa"],
    "cÃ  phÃª": ["cÃ  phÃª", "cafe", "cÃ¢y cÃ  phÃª"]
}

# 2. Template-based generation
TEMPLATES = [
    "cÃ¡ch trá»“ng {crop} á»Ÿ {area}",
    "bÃ³n phÃ¢n cho {crop} vÃ o {date}",
    "tÆ°á»›i {quantity} nÆ°á»›c cho {crop}",
    "{activity} {crop} táº¡i {area}"
]

# 3. Entity shuffling
# Giá»¯ nguyÃªn structure, thay Ä‘á»•i entity values
```

**TÃ¡c Ä‘á»™ng:** +3-5% F1 score

---

### 3. **Fine-tune Hyperparameters** â­â­â­â­

#### Thá»­ nghiá»‡m cÃ¡c cáº¥u hÃ¬nh:

```python
# train/scripts/train_ner.py

# Config A: Há»c sÃ¢u hÆ¡n
training_args = TrainingArguments(
    num_train_epochs=50,  # TÄƒng lÃªn
    learning_rate=1e-5,   # Giáº£m xuá»‘ng
    warmup_ratio=0.15,    # TÄƒng warmup
    weight_decay=0.02,    # TÄƒng regularization
)

# Config B: Batch size lá»›n hÆ¡n
training_args = TrainingArguments(
    per_device_train_batch_size=16,  # x2
    gradient_accumulation_steps=2,    # ThÃªm
    learning_rate=3e-5,               # TÄƒng LR vá»›i batch lá»›n
)

# Config C: Label smoothing
training_args = TrainingArguments(
    label_smoothing_factor=0.1,  # Giáº£m overconfidence
)
```

**CÃ¡ch test:** Cháº¡y grid search hoáº·c manual tuning
**TÃ¡c Ä‘á»™ng:** +2-4% F1 score

---

### 4. **Thá»­ Model KhÃ¡c** â­â­â­

#### So sÃ¡nh cÃ¡c models:

```python
# Current: vinai/phobert-base (135M params)
# Alternatives:

# 1. PhoBERT-large (bigger, better)
model_name = "vinai/phobert-large"  # 370M params
# Expected: +3-5% F1

# 2. XLM-RoBERTa Vietnamese
model_name = "xlm-roberta-base"
# Expected: +1-3% F1

# 3. Vietnamese BERT
model_name = "bert-base-multilingual-cased"
# Expected: Similar hoáº·c tháº¥p hÆ¡n
```

**LÆ°u Ã½:** Model lá»›n hÆ¡n = cáº§n RAM/VRAM nhiá»u hÆ¡n

**TÃ¡c Ä‘á»™ng:** +1-5% F1 score (tÃ¹y model)

---

### 5. **Cáº£i Thiá»‡n Post-processing** â­â­â­

#### ThÃªm rules thÃ´ng minh:

```python
# src/models/ner_extractor.py

def _post_process_entities(self, text, entities):
    # 1. Fix boundary issues
    # "cÃ " â†’ extend to "cÃ  chua" if found
    for entity in entities:
        if entity['type'] == 'crop_name':
            if entity['raw'] == 'cÃ ':
                # Look ahead for "chua", "phÃª", etc.
                extended = self._extend_crop_name(text, entity)
                if extended:
                    entity.update(extended)
    
    # 2. Merge adjacent entities of same type
    # "50" + "kg" â†’ "50kg" (QUANTITY)
    entities = self._merge_adjacent_entities(entities)
    
    # 3. Domain knowledge rules
    # "NPK" always FERTILIZER
    # "sensor" always DEVICE
    entities = self._apply_domain_rules(text, entities)
    
    # 4. Context-based correction
    # "bÃ³n phÃ¢n NPK" â†’ NPK must be FERTILIZER
    entities = self._context_correction(text, entities)
    
    return entities
```

**TÃ¡c Ä‘á»™ng:** +2-3% F1 score

---

### 6. **Active Learning** (Há»c Chá»§ Äá»™ng) â­â­â­â­â­

#### TÃ¬m vÃ  label nhá»¯ng examples model khÃ´ng cháº¯c cháº¯n:

```python
# train/scripts/find_uncertain_examples.py

# 1. Cháº¡y inference trÃªn unlabeled data
# 2. TÃ¬m examples vá»›i confidence tháº¥p
# 3. Manual label nhá»¯ng examples Ä‘Ã³
# 4. ThÃªm vÃ o training set
# 5. Retrain

def find_uncertain_predictions(texts, threshold=0.7):
    """Find predictions with low confidence"""
    uncertain = []
    for text in texts:
        result = ner_extractor.extract(text)
        for entity in result['entities']:
            if entity['confidence'] < threshold:
                uncertain.append({
                    'text': text,
                    'entity': entity,
                    'confidence': entity['confidence']
                })
    return uncertain
```

**TÃ¡c Ä‘á»™ng:** +5-8% F1 score (vá»›i 200-300 examples má»›i)

---

### 7. **Ensemble Methods** â­â­â­

#### Káº¿t há»£p nhiá»u models:

```python
# src/models/ner_ensemble.py

class NEREnsemble:
    def __init__(self):
        self.models = [
            NERExtractor(model_name="vinai/phobert-base"),
            NERExtractor(model_name="vinai/phobert-large"),
            RuleBasedNER()  # Fallback rules
        ]
    
    def extract(self, text):
        # Voting: Láº¥y entities mÃ  >=2 models Ä‘á»“ng Ã½
        all_predictions = []
        for model in self.models:
            all_predictions.append(model.extract(text))
        
        return self._vote(all_predictions)
```

**TÃ¡c Ä‘á»™ng:** +2-4% F1 score

---

### 8. **Curriculum Learning** â­â­â­

#### Train tá»« dá»… Ä‘áº¿n khÃ³:

```python
# train/scripts/curriculum_training.py

# Phase 1: Single entity examples (5 epochs)
easy_data = df[df['entities'].apply(lambda x: len(json.loads(x)) == 1)]

# Phase 2: 2-3 entities (5 epochs)  
medium_data = df[df['entities'].apply(lambda x: 1 < len(json.loads(x)) <= 3)]

# Phase 3: Complex multi-entity (10 epochs)
hard_data = df[df['entities'].apply(lambda x: len(json.loads(x)) > 3)]

# Train theo thá»© tá»±: easy â†’ medium â†’ hard
```

**TÃ¡c Ä‘á»™ng:** +1-3% F1 score

---

## ğŸ¯ Roadmap Thá»±c Táº¿

### **Phase 1: Quick Wins (1-2 ngÃ y)**
1. âœ… TÄƒng data lÃªn 1500 examples (manual label thÃªm 500)
2. âœ… ThÃªm post-processing rules
3. âœ… Tune hyperparameters (test 3-4 configs)

**Expected:** F1 = 0.85

---

### **Phase 2: Medium Effort (3-5 ngÃ y)**
1. âœ… Data augmentation (táº¡o thÃªm 1000 synthetic examples)
2. âœ… Active learning (label 200 uncertain cases)
3. âœ… Thá»­ PhoBERT-large

**Expected:** F1 = 0.88-0.90

---

### **Phase 3: Advanced (1-2 tuáº§n)**
1. âœ… Curriculum learning
2. âœ… Ensemble 2-3 models
3. âœ… Domain-specific fine-tuning

**Expected:** F1 = 0.92+

---

## ğŸ“Š Æ¯u TiÃªn Theo ROI

| Chiáº¿n lÆ°á»£c | Effort | Impact | ROI | Priority |
|-----------|--------|--------|-----|----------|
| ThÃªm data | Medium | Very High | â­â­â­â­â­ | **1** |
| Active Learning | Medium | Very High | â­â­â­â­â­ | **2** |
| Post-processing | Low | Medium | â­â­â­â­ | **3** |
| Data Augmentation | Low | Medium | â­â­â­â­ | **4** |
| Hyperparameter Tuning | Medium | Medium | â­â­â­ | **5** |
| Ensemble | High | Medium | â­â­ | 6 |
| PhoBERT-large | Low | Medium | â­â­â­ | **7** |
| Curriculum Learning | High | Low | â­ | 8 |

---

## ğŸ› ï¸ Báº¯t Äáº§u Ngay

### Step 1: ThÃªm Data (Æ¯u tiÃªn cao nháº¥t)

```bash
# 1. Táº¡o template Ä‘á»ƒ label nhanh
# 2. Label thÃªm 500 examples
# 3. Update ner_data.csv
# 4. Retrain

cd train/scripts
python train_ner.py
```

### Step 2: Implement Post-processing

```python
# Edit src/models/ner_extractor.py
# ThÃªm cÃ¡c rules thÃ´ng minh vÃ o _post_process_entities()
```

### Step 3: Hyperparameter Tuning

```bash
# Test 3-4 configs khÃ¡c nhau
# Chá»n config tá»‘t nháº¥t
```

---

## ğŸ’¡ Tips

1. **Track experiments:** Ghi láº¡i má»—i thay Ä‘á»•i vÃ  F1 score tÆ°Æ¡ng á»©ng
2. **Validation set:** LuÃ´n dÃ¹ng cÃ¹ng 1 validation set Ä‘á»ƒ compare
3. **Error analysis:** Xem model sai á»Ÿ Ä‘Ã¢u, táº­p trung fix nhá»¯ng cases Ä‘Ã³
4. **Incremental:** Thay Ä‘á»•i 1 thá»© 1 lÃºc, Ä‘á»«ng thay Ä‘á»•i nhiá»u thá»© cÃ¹ng lÃºc

---

## ğŸ“ˆ Expected Timeline

- **Week 1:** F1 = 0.80 â†’ 0.85 (thÃªm data + post-processing)
- **Week 2:** F1 = 0.85 â†’ 0.88 (augmentation + active learning)
- **Week 3+:** F1 = 0.88 â†’ 0.92+ (advanced techniques)

**Má»¥c tiÃªu thá»±c táº¿:** F1 = 0.90 trong 2-3 tuáº§n! ğŸ¯
